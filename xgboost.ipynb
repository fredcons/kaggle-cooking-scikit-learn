{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "recipes = pd.read_json(\"train.json\", orient = \"records\", dtype = {\"cuisine\" : \"str\", \"id\" : \"int64\", \"ingredients\" : \"str\"})\n",
    "recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize.regexp import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.metrics import *\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from sklearn.feature_extraction import text \n",
    "\n",
    "cooking_stop_words = ['fat', 'free', 'minced', 'ground', 'fresh', 'dried', 'chopped', 'large', 'small', 'cooked', 'purpose', 'kosher', 'extra', \n",
    "                      'low', 'sodium', 'baked', 'diced', 'minced', 'crushed', 'hot', 'cold', 'roasted', 'toasted', 'plain', 'warm']\n",
    "all_stop_words = text.ENGLISH_STOP_WORDS.union(cooking_stop_words)\n",
    "\n",
    "class StemTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(min_df=1, token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]+\\b\", strip_accents='ascii', stop_words=all_stop_words)\n",
    "        self.analyzer = self.vectorizer.build_analyzer()\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.reference_words = []\n",
    "    def __call__(self, doc):\n",
    "        raw_tokens = self.analyzer(doc)\n",
    "        return [self.stemmer.stem(t) for t in self.analyzer(doc)]\n",
    "    \n",
    "class StemNounsTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(min_df=1, token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]+\\b\", strip_accents='ascii', stop_words=all_stop_words)\n",
    "        self.analyzer = self.vectorizer.build_analyzer()\n",
    "        self.stemmer = PorterStemmer()\n",
    "        self.reference_words = []\n",
    "    def __call__(self, doc):\n",
    "        raw_tokens = self.analyzer(doc)\n",
    "        filtered_words = []\n",
    "        for token,tag in pos_tag(raw_tokens):\n",
    "            if tag != 'JJ':\n",
    "                filtered_words.append(token)\n",
    "        return [self.stemmer.stem(t) for t in filtered_words]    \n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=2, tokenizer=StemTokenizer(), strip_accents='ascii', dtype=np.float32, max_features = 2000)\n",
    "ingredients_features = vectorizer.fit_transform(recipes[\"ingredients\"])\n",
    "ingredients_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names()[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_counts = np.sum(ingredients_features.toarray(), axis=0)\n",
    "features_counts = pd.DataFrame({'feature_name': vectorizer.get_feature_names(), 'feature_count': token_counts})\n",
    "features_counts = features_counts.sort('feature_count', ascending=False)\n",
    "features_counts.to_csv(\"features_with_counts.csv\", index=False, columns=(\"feature_name\", \"feature_count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(recipes[\"cuisine\"])\n",
    "recipes[\"cuisine_encoded\"] = le.transform(recipes[\"cuisine\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "recipes_train_data_xgb, recipes_test_data_xgb, recipes_train_result_xgb, recipes_test_result_xgb = train_test_split(ingredients_features, recipes[\"cuisine_encoded\"], test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(recipes_train_data_xgb.toarray(), label=recipes_train_result_xgb)\n",
    "dtest = xgb.DMatrix(recipes_test_data_xgb.toarray(), label=recipes_test_result_xgb)\n",
    "\n",
    "xgb_params['bst:max_depth'] = 40\n",
    "xgb_params['bst:eta'] = 0.2\n",
    "xgb_params['silent'] = 0\n",
    "xgb_params['objective'] = 'multi:softmax'\n",
    "xgb_params['num_class'] = 20\n",
    "xgb_params['nthread'] = 2\n",
    "xgb_params['eval_metric'] = 'merror'\n",
    "\n",
    "evallist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "\n",
    "num_round = 200\n",
    "bst = xgb.train(xgb_params, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recipes_test = pd.read_json(\"test.json\", orient = \"records\", dtype = {\"cuisine\" : \"str\", \"id\" : \"int64\", \"ingredients\" : \"str\"})\n",
    "ingredients_test_features = vectorizer.transform(recipes_test[\"ingredients\"])\n",
    "ingredients_test_matrix = xgb.DMatrix(ingredients_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predicted = bst.predict(ingredients_test_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_predicted = np.array(test_predicted, dtype=\"int32\")\n",
    "predicted_labels = le.inverse_transform(test_predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'id': recipes_test[\"id\"], 'cuisine': predicted_labels})\n",
    "test_df.to_csv(\"result_xgboost.csv\", index=False, columns=(\"id\", \"cuisine\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
